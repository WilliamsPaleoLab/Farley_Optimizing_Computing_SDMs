---
title: "Optimization Routines: Random Forest"
output:
  html_document:
    highlight: tango
    theme: spacelab
    toc: no
  pdf_document:
    toc: yes
---

## Approach
### Uncontrained Optimization

1. Use a combination of prediction and interpolation to predict all values oftime and accuracy under different hardware/software configurations.
2. Find the minimal combination of algorithm inputs that maximize accuracy. If there are ties, break them by using the point that requires the least data.
3. Find the costs associated with running the algorithm with those inputs on all different hardware configurations.
4. Find the combination of hardware that jointly minimizes cost and time.

### Data-contrained Optimization
1.  Use a combination of prediction and interpolation to predict all values oftime and accuracy under different hardware/software configurations.
2.  Subset the accuracy surface produced above to the amount of data available.  The maximizing point will fall in the upper right corner of the subsetted space.
3.  Find the costs associated with running the algorithms with the accuracy-maximizing point on all different hardwares.
4.  Find the combination of hardware that jointly minimizes time and cost.

### Cost-constrained Optimization
1.  Use a combination of prediction and interpolation to predict all values oftime and accuracy under different hardware/software configurations.
2.  Subset the space produced above to the amount of time and money able to be spent on modelling.  
3.  Working backwards now, find the accuracies that can be produced in the limited time.
4.  Using the subset of accuracy space, find the combination of algorithm inputs that maximizes accuracy.
5.  Optional: Find the combiation of hardware that jointly minimizes time and cost.  This allows you to find out if there's a cheaper way to get the same result that using all of your time and money.


```{r setup}
library(ggplot2)
options(java.parameters = "-Xmx1500m")
library(bartMachine)
library(reshape2)
knitr::opts_chunk$set(cache=TRUE, echo=F, warning=F, error = F, message=F)
knitr::opts_knit$set(root.dir = "/users/scottsfarley/documents")
setwd("/users/scottsfarley/documents")
library(parallel)
library(doParallel)
```


First, get the training data and fit the model.  Perform some skill checks on it.
```{r modelFitting}
res <- read.csv("thesis-scripts/data/rf_full.csv")
res <- res[c("totalTime", "fittingTime", "cores", "GBMemory", "trainingExamples", "numPredictors", "cells", "method")]
# dummy variables for method factor
res$seq<- 0
res$seq[res$method == 'SERIAL'] <- 1
res$par <- 0
res$par[res$method == "PARALLEL"] <- 1
rf.testingInd <- sample(nrow(res), nrow(res) * 0.2)
rf.testing <- res[rf.testingInd,]
rf.training <- res[-rf.testingInd,]
rf.training.predictors <- rf.training[c( "numPredictors", "cores", "GBMemory", "trainingExamples", 'cells', "par", "seq")]
rf.training.predictors <- data.frame(rf.training.predictors)
rf.training.response <- log(rf.training[[c("totalTime")]]) ## take the log for prediction
rf.rf <- bartMachine(rf.training.predictors, rf.training.response, serialize=T, verbose = F)


## do prediction
rf.testing.predictors <- rf.testing[c( "numPredictors", "cores", "GBMemory", "trainingExamples", 'cells', "par", "seq")]
rf.testing.predictors <- data.frame(rf.testing.predictors)
rf.prediction <- predict(rf.rf, rf.testing.predictors)

## get statistics
rf.mdCor <- cor(rf.prediction, log(rf.testing[['totalTime']]))
rf.mdDelta <- rf.prediction - log(rf.testing$totalTime)
rf.mdDelta.mean <- mean(rf.mdDelta)
rf.mdDelta.sd <- sd(rf.mdDelta)
rf.mdDelta.RSS <- sum((rf.mdDelta)^2)
rf.mse <- rf.mdDelta.RSS / length(rf.prediction)
rf.r2 <- rf.mdCor ^ 2

## Plot
plot(rf.prediction ~ log(rf.testing[['totalTime']]), 
     xlab="Observed", ylab="Predicted", main="Observed-Predicted Execution Time (RF)")
abline(0, 1)

print(paste("Runtime Model Mean Squared Error: ", rf.mse))
print(paste("Runtime Model Percent Variance Explained: ", rf.r2, "%"))

rf.post <- bart_machine_get_posterior(rf.rf, rf.testing.predictors)
rf.post <- data.frame(rf.post$y_hat_posterior_samples)
rf.post$sd <- apply(rf.post, 1, sd)
rf.post.sdMean <- mean(rf.post$sd)
print(paste("Runtime Model Posterior Mean Standard Deviation: ", rf.post.sdMean))




### Fit the accuracy model
res <- read.csv("thesis-scripts/data/rf_full.csv")
res$seq<- 0
res$seq[res$method == 'SERIAL'] <- 1
res$par <- 0
res$par[res$method == "PARALLEL"] <- 1

rf.testingInd.acc <- sample(nrow(res), nrow(res) * 0.2)
rf.testing.acc <- res[rf.testingInd.acc,]
rf.training.acc <- res[-rf.testingInd.acc,]

rf.training.predictors.acc <- rf.training.acc[c( "numPredictors", "cores", "GBMemory", "trainingExamples", 'cells')]

rf.training.predictors.acc <- data.frame(rf.training.predictors.acc)
rf.training.response.acc <- rf.training.acc[[c("testingAUC")]] 

rf.acc.rf <- bartMachine(rf.training.predictors.acc, rf.training.response.acc, serialize=T, verbose=F)

## do prediction
rf.testing.predictors.acc <- rf.testing.acc[c( "numPredictors", "cores", "GBMemory", "trainingExamples", 'cells')]
rf.testing.predictors.acc <- data.frame(rf.testing.predictors.acc)
rf.prediction.acc <- predict(rf.acc.rf, rf.testing.predictors.acc)

## get statistics
rf.mdCor.acc <- cor(rf.prediction.acc, rf.testing.acc[['testingAUC']])
rf.mdDelta.acc <- rf.prediction.acc - rf.testing.acc$testingAUC
rf.mdDelta.mean.acc <- mean(rf.mdDelta.acc)
rf.mdDelta.sd.acc <- sd(rf.mdDelta.acc)
rf.mdDelta.RSS.acc <- sum((rf.mdDelta.acc)^2)
rf.r2.acc <- rf.mdCor.acc ^ 2
rf.mse.acc <- rf.mdDelta.RSS.acc / length(rf.prediction.acc)


## Plot
plot(rf.prediction.acc ~ rf.testing.acc[['testingAUC']], 
     xlab="Observed AUC", ylab="Predicted AUC", main="Observed-Predicted AUC (RF)")
abline(0, 1)

print(paste("Accuracy Model Mean Squared Error: ", rf.mse.acc))
print(paste("Accuracy Model Percent Variance Explained: ", rf.r2.acc, "%"))

rf.post.acc <- bart_machine_get_posterior(rf.acc.rf, rf.testing.predictors.acc)
rf.post.acc <- data.frame(rf.post.acc$y_hat_posterior_samples)
rf.post.acc$sd <- apply(rf.post.acc, 1, sd)

rf.post.acc.sdMean <- mean(rf.post.acc$sd)
print(paste("Accuracy Model Posterior Mean Standard Deviation: ", rf.post.acc.sdMean))
```



Choose a finite number of possible solutions to the model.  Ideally, we would want every single combination of predictor variables [0, Inf].  This is obviously intractable.  Moreover, I only have data for a subset of that space anyways.  So randomly sample the subspace in which I have data to make the problem possible to solve.

```{r subset}
cores <- seq(1, 10)
GBMemory <- seq(1, 10)
trainingExamples <- seq(0, 10000, by=1000)
numPredictors <- seq(1, 5)
cells <- 100000

prices <- read.csv("/users/scottsfarley/documents/thesis-scripts/data/costs.csv")

## make the hypergrid
scenario <- expand.grid(numPredictors = numPredictors,
                        # cores = cores,
                        # GBMemory = GBMemory,
                        trainingExamples = trainingExamples,
                        cells = cells,
                        config = unique(prices$ConfigurationNumber))

for (value in unique(scenario$config)){
  rateRow = prices[which(prices$ConfigurationNumber == value), ]
  rate = rateRow$TotalRate
  cores = rateRow$CPUs
  mem = rateRow$GBsMem
  scenario$TotalRate[scenario$config == value] = rate
  scenario$cores[scenario$config == value] = cores
  scenario$GBMemory[scenario$config == value] = mem
}
```


Using that subset of data and the models we fit previously, predict each candidate configuration of algorithm inputs and hardware variables for execution time and SDM accuracy.
```{r}
scenario.acc <- scenario[c("numPredictors", "trainingExamples", "cells", 
                           "cores", "GBMemory")]
p.acc <- predict(rf.acc.rf, scenario.acc)


scenario.time <- scenario[c("numPredictors", "trainingExamples", "cells", "cores", "GBMemory")]
scenario.time$seq <- 0
scenario.time$par <- 1
## split here because my computer is stupid and runs out of heap space
p.time.1 <- predict(rf.rf, scenario.time)
p.time <- c(p.time.1)
scenario$accuracy <- p.acc
scenario$seconds <- exp(p.time)
scenario$cost <- scenario$seconds * scenario$TotalRate
```

Plot the posterior means of the accuracy models against the algorithm inputs that should control accuracy. In this case, these are number of training examples and number of covariates.
```{r plotAccuracy}
i.acc <- interp(x = scenario$numPredictors, 
                y = scenario$trainingExamples, 
                z = scenario$accuracy, 
                xo = seq(1, 5),
                yo = seq(1, 10000),
                duplicate=T)

i.acc <- interp2xyz(i.acc, data.frame = T)


ggplot(i.acc, aes(x, y, z = z)) +
  geom_tile(aes(fill=z), height=1, width=1) +
  stat_contour(binwidth=0.05, col='black', lwd=0.25) +
  ggtitle("Random Forest Accuracy Surface") +
  xlab("Number of Covariates") +
  ylab("Number of Training Examples") +
  scale_fill_continuous(low='pink', high='forestgreen')
```


The accuracy clearly varies from low (few training examples and few covariates) to very high (many covariates, many training examples).  Perhaps more data would be helpful here, but what are you going to do. Our task is to find the combinations of inputs that results in the highest accuracy model. If there's a tie, find the combination that needs the least data.    

Now, we know the combination of algorithm inputs that result in the highest accuracy.  The figure below shows the combination identified on the training examples and covariates axes.  This combination of training examples and number of covariates can be run on any combination of hardware.  Some might be suboptimal.  Thus, at this point, we've solved half of our challenge: algorithm inputs have been optimized, now it's time optimize hardware.


```{r checkHardwareEffect}
### select the combination that has the highest accuracy
## order by the things that control accuracy
## first by training examples, then by num predictors
## select the highest accuracy with the lowest valued predictors
sortedScenario <- i.acc[order(i.acc$y, i.acc$x),]
maxID <- which.max(sortedScenario$z)
theMax <- sortedScenario[maxID, ]
print(paste("Accuracy is maximized at", theMax$y, "training examples and", theMax$x, "predictors."))

theMax.trainingExamples <- theMax$y
theMax.numPredictors <- theMax$x
theMax.expectedAccuracy <- theMax$z
theMaxSet <- scenario[scenario$trainingExamples == theMax.trainingExamples &
                              scenario$numPredictors == theMax.numPredictors, ]


names(i.acc) <- c("numPredictors", "trainingExamples", "accuracy")
## plot the max onto the surface from before
ggplot(i.acc, aes(numPredictors, trainingExamples, z = accuracy)) +
  geom_tile(aes(fill=accuracy), height=1, width=0.5) +
  stat_contour(binwidth=0.05, col='black') +
  ggtitle("Random Forest Accuracy Surface") +
  xlab("Number of Covariates") +
  ylab("Number of Training Examples") +
  scale_fill_continuous(low='pink', high='forestgreen') +
  geom_point(data=theMaxSet, aes(x = numPredictors , y = trainingExamples), shape=25, fill='red', size=3)
```

Now you might say, well that doesn't really loook like it took the combiation that best fit the data.  Did it really choose the highest accuracy? When we plot out all possible accuracies, we see that, yes, it does look really good. 

```{r}
ggplot(i.acc) +
  geom_point(aes(y = accuracy, x = seq(1, length(accuracy)))) +
  geom_point(aes(y = theMax.expectedAccuracy, x=maxID), shape=25, fill='red', size=3) +
  ggtitle("Potential Accuracies") +
  ylab("Accuracy (AUC)") +
  xlab("Combination of Inputs")
```


In theory, the hardware parameters should not affect the SDM accuracy.  We can test this assumption here, by plotting the accuracies obtained for this combination of algorithm inputs against modeled accuracy on the number of CPUs and amount of memory.  If the assumption is valid, the plot should show no change in either the horizontal or vertical directions.  We see that there is, in fact, some change, though.  This is likely due to expeirmental design, and lack of a full factorial design setup.  The effect is realtively minor, and I choose to comment it and move along. 

```{r accAssumptionCheck}
ggplot(theMaxSet) +
  geom_tile(aes(x = cores, y=GBMemory, z=accuracy, fill=accuracy)) +
  #geom_contour(aes(x = cores, y=GBMemory, z=accuracy, fill=accuracy)) +
  ggtitle("Random Forest Hardware/Accuracy Surface") +
  xlab("CPU Cores") +
  ylab("RAM (GB)") +
  scale_fill_continuous(low='blue', high='red')

acc.diff <- max(theMaxSet$accuracy) - min(theMaxSet$accuracy)
acc.diffFromExp <- mean(theMaxSet$accuracy) - theMax.expectedAccuracy
print(paste("Accuracy Range on Hardware: ", acc.diff))
print(paste("Accuracy Range from Expectation: ", acc.diffFromExp))
print(paste("Model Posterior Mean Standard Deviation: ", rf.post.acc.sdMean))
```

Now we've fixed accuracy to be a single point (or really a PDF, but we're just working with the posterior means right now).  Project that point into time and cost space using the modeled time and cost for that combination of algorithm inputs.

```{r timeCostProjection}
ggplot(theMaxSet) +
  geom_point(aes(x = cost, y = seconds))+
  ggtitle("Random Forest Time/Cost Surface") +
  xlab("Cost (cents)") +
  ylab('Cost (seconds)') 
```

The optimal solution is the one that balances time and cost equally during the minimization. We use euclidean distance here, which normalizes each dimension by its standard deviation, so they are weighted equally. For each candidate combiantion of hardware, we calculate the distance between it and the origin of these two axes.  We then find the minimum of that distance matrix and call that point the optimal.

```{r distCalc}
origin <- rep(0, length(theMaxSet))
candidates <- rbind(theMaxSet, origin)
d <- as.matrix(dist(candidates, "euclidean"))
fromOrigin <- d[,nrow(candidates)]
fromOrigin <- fromOrigin[fromOrigin > 0]
fromOrigin <- as.numeric(fromOrigin)
minDistIdx <- which.min(fromOrigin)
optimal <- theMaxSet[minDistIdx, ]

xend = optimal$seconds
yend = optimal$cost

## Plot the same thing, but now with the optimal marked
ggplot(theMaxSet) +
  geom_point(aes(x = cost, y = seconds)) +
  ggtitle("Random Forest Time/Cost Surface") +
  xlab("Cost (cents)") +
  ylab('Cost (seconds)')  +
  geom_segment(aes(x = 0, y=0, xend=cost, yend=seconds), alpha=0.075) +
  geom_point(data=optimal, aes(x = cost, y = seconds), col='red', size=3, shape=25)

```

Our job is complete. We've optimized both the harware and software dimensions of the problem. 

```{r printRes}
print("------RANDOM FOREST OPTIMAL--------")
print(paste("Predicted Optimal Accuracy", theMax.expectedAccuracy, "+/-", abs(acc.diffFromExp)))
print(paste("Predicted Optimal Cost (seconds)", optimal$seconds))
print(paste("Predicted Optimal Cost (cents)", optimal$cost))
print(paste("Cores: ", optimal$cores))
print(paste("Memory:", optimal$GBMemory))
print(paste("Training Examples:", theMax$trainingExamples))
print(paste("Covariates:", theMax$numPredictors))
```


This was all done using the mean of the posterior distribution.  This works pretty well, and I'm happy with the results, but I loose a lot of information by throwing away the distribution.  Let's try to incorporate the posterior samples now, when possible. We'll go through the same steps, but instead of putting a single value of time and cost, we'll put 1000 posterior samples. We'll keep accuracy in terms of the posterior mean, though, because it get's really complicated if you are allowed multiple combinations of inputs into the algorithm.

```{r bayesSetup}
theMaxSet.time <- theMaxSet[c("numPredictors", "trainingExamples", "cells", "cores", "GBMemory")]
theMaxSet.time$par <- 1
theMaxSet.time$seq <- 0
time.post <- bart_machine_get_posterior(rf.rf, theMaxSet.time)$y_hat_posterior_samples
time.post <- data.frame(time.post)
time.post$cores <- theMaxSet$cores
time.post$GBMemory <- theMaxSet$GBMemory
time.post$config <- theMaxSet$config
time.post$TotalRate <- theMaxSet$TotalRate
```

So we've kept the optimal combination of training examples and number of covariates.  Take this combination, and use the model to estimate time and cost for every available combination of hardware.

If you were wondering, we really do use the posterior means.

```{r}
library(plyr)
time.post$postMeanTime <- rowMeans(time.post[, 1:1000])
time.post$postMeanTime <- exp(time.post$postMeanTime)
time.post$postMeanCost <- time.post$postMeanTime * time.post$TotalRate

ggplot(time.post) + 
  geom_point(aes(x = postMeanCost, y = postMeanTime), shape=20, col='green', size=2) +
  geom_point(data = theMaxSet, aes(x = cost, y = seconds), col='red', size=2, shape=25)

```

```{r plot}
## get the data frame ready for plotting
c.d <- melt(time.post, id.vars = c("cores", "GBMemory", "config", "TotalRate"))
c.d <- na.omit(c.d)
c.d$value <- exp(c.d$value)
c.d$CostSample <- c.d$value * c.d$TotalRate
c.d$config <- as.factor(c.d$config)
ggplot(c.d) +
  geom_point(aes(x = CostSample, y = value, col=config), alpha=0.05) +
  scale_color_discrete(guide=F) +
  geom_point(data=time.post, aes(x = postMeanCost, y = postMeanTime), shape=20, size=2) +
  ggtitle("Time/Cost Posterior Estimates") +
  xlab("Cost") +
  ylab("Time")
```

Take every point inside of every configuration's distribution, and calculate its distance from the origin. This gives us a density estimate of each configuration's distance from the origin, giving us the ability to quantify the optimality of the minimal solution.
```{r}
### okay, so we've got the posteriors for time and cost, now we can use them in calculating the optimal distnace

compDists <- list()
for (i in 1:nrow(time.post)){
  compDist <- vector()
  thisRate <- as.numeric(as.character(theMaxSet$TotalRate[i]))
  for (j in 1:1000){ ## 1000 posterior samples
    t.i <- as.numeric(as.character(time.post[[j]][[i]])) ## psoterior of time for this config
    c.i <- t.i * thisRate ## make cost posterior from time samples times rate
    pt <- c(t.i, c.i)
    orig <- c(0, 0)
    m <- rbind(pt, orig)
    d <- dist(m)
    compDist[j] <- d[[1]]
  }
  compDists[[i]] <- compDist
}
allDistances <- melt(compDists)

p <- na.omit(allDistances)
p$value <- as.numeric(p$value)
p$L1 <- as.factor(p$L1)
ggplot(p) + 
  geom_density(aes(x=value, group=L1, col=L1), alpha=0.2) +
  scale_fill_brewer('Dark2', guide=FALSE) + guides(colour=FALSE, L1=F) +
  xlab("Euclidiean Distance From Origin") +
  ggtitle("Density of Euclidean Distance From Origin") +
  geom_rug(aes(x =value , group=L1, col=L1))
```

There's a lot of overlab in this figure, and many points are far away from the optimal.  We don't care about those.  Take the ten closest to the minimum and look at their distributions.
```{r minimalDistributions}
post.timeCost.sorted <- p[order(p$value),]
candidates <- unique(post.timeCost.sorted$L1)[1:10]

## select their whole distributions
candidate.dist <- post.timeCost.sorted[post.timeCost.sorted$L1 %in% candidates, ]
ggplot(candidate.dist) + 
  geom_density(aes(x=value, group=L1, col=L1), alpha=0.2) +
  scale_fill_brewer('Dark2', guide=FALSE) + guides(colour=FALSE, L1=F) +
  xlab("Euclidiean Distance From Origin") +
  ggtitle("Density of Euclidean Distance From Origin") +
  geom_rug(aes(x =value , group=L1, col=L1))

```

Now, the optimal configuration may be one of the following:
```{r minimalDistTable}
candiateConfigs <- theMaxSet[theMaxSet$config %in% candidates, ]
candiateConfigs <- candiateConfigs[c("config", "cores", "GBMemory", "seconds", "cost")]
library(knitr)
kable(candiateConfigs, row.names = F)
```

In the results above, you're accutally seeing the trade off between time and money play out quite nicely.  Adding cores costs money, but, in the case of random forests, reduces time. Here, that tradeoff basically exactly evens out.

```{r}
library(akima)
i.time <- interp(x = scenario$cores, 
                y = scenario$GBMemory, 
                z = scenario$seconds, 
                xo = seq(1, 22),
                yo = seq(1, 22, by=0.25),
                duplicate=T)

i.time <- interp2xyz(i.time, data.frame=T)

names(i.time) <- c("Cores", "GBMemory", "Seconds")
i.time$config <- interaction(i.time$Cores, i.time$GBMemory)
i.time$TotalRate <- 0
for (value in levels(i.time$config)){
  testRow <- i.time[which(i.time$config == value), ]
  testCores <- round(testRow$Cores)
  testGB <- round(testRow$GBMemory)
  rateRow = prices[which(prices$CPUs == testCores & prices$GBsMem == testGB), ]
  rate = rateRow$TotalRate
  if(is.null(rate)){
    rate = 0
  }
  if(length(rate) == 0){
    rate = 0
  }
  i.time$TotalRate[i.time$config == value] = rate
}

i.time$cost <- i.time$TotalRate * i.time$Seconds


threshold.time <- 15 ##seconds
threshold.cost <- 15 ##cents
i.subset <- scenario[scenario$cost < threshold.cost & scenario$seconds < threshold.time, ]

maxTex <- max(i.subset$trainingExamples)
maxNP <- max(i.subset$numPredictors)

subset.acc.interp <- interp(x = i.subset$trainingExamples,
                            y = i.subset$numPredictors,
                            z = i.subset$accuracy,
                            xo = seq(0, maxTex),
                            yo = seq(1, maxNP), duplicate = T)

subset.acc.interp <- interp2xyz(subset.acc.interp, data.frame=T)

names(subset.acc.interp) <-c("trainingExamples", "numPredictors", "accuracy")

ggplot(subset.acc.interp, aes(numPredictors, trainingExamples, z = accuracy)) +
  geom_tile(aes(fill=accuracy), height=1, width=0.5) +
  stat_contour(binwidth=0.05, col='black') +
  ggtitle("Random Forest Accuracy Surface") +
  xlab("Number of Covariates") +
  ylab("Number of Training Examples") +
  scale_fill_continuous(low='pink', high='forestgreen') 
```

```{r}
sortedScenario <- subset.acc.interp[order(subset.acc.interp$trainingExamples,
                                          subset.acc.interp$numPredictors),]
maxID <- which.max(sortedScenario$accuracy)
theMax <- sortedScenario[maxID, ]
print(paste("Accuracy is maximized at", theMax$trainingExamples, "training examples and", theMax$numPredictors, "predictors."))

theMax.trainingExamples <- theMax$trainingExamples
theMax.numPredictors <- theMax$numPredictors
theMax.expectedAccuracy <- theMax$accuracy
theMaxSet <- scenario[scenario$trainingExamples == theMax.trainingExamples &
                              scenario$numPredictors == theMax.numPredictors, ]


## plot the max onto the surface from before
ggplot(subset.acc.interp, aes(numPredictors, trainingExamples, z = accuracy)) +
  geom_tile(aes(fill=accuracy), height=1, width=0.5) +
  stat_contour(binwidth=0.05, col='black') +
  ggtitle("Random Forest Accuracy Surface") +
  xlab("Number of Covariates") +
  ylab("Number of Training Examples") +
  scale_fill_continuous(low='pink', high='forestgreen') +
  geom_point(data=theMaxSet, aes(x = numPredictors , y = trainingExamples), shape=25, fill='red', size=3)

```